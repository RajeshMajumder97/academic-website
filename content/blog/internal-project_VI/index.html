---
date: "2021-10-26T00:00:00Z"
external_link: ""
image:
#  caption: Photo by rawpixel on Unsplash
  focal_point: Smart
  
#slides: example
summary: Understanding Monte Carlo Simulation in R.
tags:
- Blogs
title: Simulation & Statistics in R
categories: 
- R

output:
  blogdown::html_page:
    toc: true
  
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">INTRODUCTION</a></li>
<li><a href="#concept-of-simulation">Concept Of Simulation</a></li>
<li><a href="#why-do-we-simulate">Why do we simulate ?</a></li>
<li><a href="#drawing-of-simple-random-sample">Drawing of Simple Random Sample</a></li>
<li><a href="#example">Example</a></li>
<li><a href="#unequal-probability-sampling">Unequal Probability Sampling</a></li>
<li><a href="#similating-coin-tosses">Similating Coin Tosses</a></li>
<li><a href="#find-the-proportion-of-heads-tails-in-long-run">Find the Proportion of heads &amp; tails in long run</a></li>
<li><a href="#find-the-proportion-of-heads-tails-in-long-run-1">Find the Proportion of heads &amp; tails in long run</a></li>
<li><a href="#finding-probabilities">Finding Probabilities</a>
<ul>
<li><a href="#fact">Fact</a></li>
</ul></li>
<li><a href="#drawing-a-card">Drawing a Card</a></li>
<li><a href="#divisibility-test">Divisibility Test</a></li>
<li><a href="#urn-ball-problem">Urn-Ball Problem</a></li>
<li><a href="#urn-ball-problem-1">Urn-Ball Problem</a></li>
<li><a href="#birthday-problem">Birthday Problem</a></li>
<li><a href="#card-shiffting">Card Shiffting</a></li>
<li><a href="#cut-shuffle">Cut Shuffle</a></li>
<li><a href="#simulating-a-cut-shuffle">Simulating a Cut Shuffle</a></li>
<li><a href="#riffle-shuffle">Riffle Shuffle</a></li>
<li><a href="#simulating-riffle-shuffle">Simulating Riffle Shuffle</a></li>
<li><a href="#simulating-riffle-shuffle-1">Simulating Riffle Shuffle</a></li>
<li><a href="#simulating-random-variables">Simulating Random Variables</a></li>
<li><a href="#using-it-farther">Using it farther</a></li>
<li><a href="#much-complicated-ones">Much Complicated Ones</a>
<ul>
<li><a href="#fact-1">Fact</a></li>
<li><a href="#algorithm">Algorithm</a></li>
</ul></li>
<li><a href="#generating-poisson-distribution">Generating Poisson Distribution</a></li>
<li><a href="#continuous-distributions">Continuous Distributions</a>
<ul>
<li><a href="#fact-2">Fact</a></li>
</ul></li>
<li><a href="#working-with-inbuilt-r-functions">Working with inbuilt R functions</a></li>
<li><a href="#plotting-the-normal-density">Plotting the normal density</a></li>
<li><a href="#other-standard-distributions-in-r">Other Standard Distributions in R</a></li>
<li><a href="#central-limit-theorem">Central Limit Theorem</a>
<ul>
<li><a href="#theorem">Theorem</a></li>
</ul></li>
<li><a href="#law-of-laege-numbers">Law of Laege Numbers</a></li>
<li><a href="#plotting-the-probability">Plotting the Probability</a></li>
<li><a href="#strong-law-of-large-numbers">Strong Law of large numbers</a></li>
<li><a href="#illustrating-strong-law">Illustrating Strong Law</a></li>
<li><a href="#family-planning">Family Planning</a></li>
<li><a href="#using-simulation-to-construct-tests">Using Simulation to construct Tests</a></li>
<li><a href="#plot-of-beta-densities">Plot of Beta Densities</a></li>
<li><a href="#what-type-of-test-shall-we-perform">What type of test shall we perform ?</a></li>
<li><a href="#now-lets-find-the-c">Now lets find the c</a></li>
<li><a href="#generating-normal-variables">Generating Normal Variables</a>
<ul>
<li><a href="#fact-box-muller-transformation">Fact: Box-Muller transformation</a></li>
</ul></li>
<li><a href="#generating-bivariate-normal-variables">Generating Bivariate Normal Variables</a>
<ul>
<li><a href="#fact-3">Fact:</a></li>
</ul></li>
<li><a href="#monte-carlo-simulation">Monte Carlo Simulation</a></li>
<li><a href="#bias-variance">Bias &amp; Variance</a></li>
<li><a href="#monte-carlo-integration">Monte Carlo Integration</a>
<ul>
<li><a href="#example-1">Example</a></li>
<li><a href="#another-example">Another Example</a></li>
</ul></li>
<li><a href="#an-assignment-problem">An assignment Problem</a></li>
<li><a href="#brownian-motion">Brownian Motion</a></li>
</ul>
</div>

<div id="introduction" class="section level2">
<h2>INTRODUCTION</h2>
<p>As a statistician, we Want to deal with random experiments. So to do that, thare are various techniques to predict the outcome of such experiments :</p>
<ul>
<li><p><strong>Wait and See:</strong> Designing winning strategies by trial-and-error method.</p></li>
<li><p><strong>Solving Probability Models:</strong> Assume a definite mathematical model to predict outcome, sometimes gets complicated.</p></li>
<li><p><strong>Simulate Probability Models:</strong> Also start with a mathematical model, but instead of computing it mathematically we use computers to perform the virtual random experiment following that model and then analyze the artificial data generated by computers. Similar to “wait and see” except that we do not need to wait long reality.</p></li>
</ul>
</div>
<div id="concept-of-simulation" class="section level2">
<h2>Concept Of Simulation</h2>
<ul>
<li><p>Assume a mathematical model.</p></li>
<li><p>Use computers to perform the random experiment artificially.</p></li>
<li><p>Computers can do artificial random experiment as computers can generate random numbers.</p></li>
<li><p>Use the artificial data generated by the computers to analyze the model and predict the outcome.</p></li>
<li><p>Note that, <em>the random numbers generated by computers are not random in absolute sense, they are only pseudo-random numbers.</em></p></li>
</ul>
</div>
<div id="why-do-we-simulate" class="section level2">
<h2>Why do we simulate ?</h2>
<ul>
<li><p>To have a better understanding of the known probability models.</p></li>
<li><p>To visualize a probability model with examples of outcome of a random experiment ( <em>which in reality are hard to obtain</em> )</p></li>
<li><p>To have an idea about the result of a statistical model which cannot be solved explicitly using formula.</p></li>
<li><p>To judge the performance a model before applying it to a real data situation.</p></li>
</ul>
</div>
<div id="drawing-of-simple-random-sample" class="section level2">
<h2>Drawing of Simple Random Sample</h2>
<ul>
<li>We use the sample() command for both <strong>with-replacement</strong> &amp; <strong>with-out-replacement</strong> sampling.</li>
</ul>
<pre class="r"><code>set.seed(123)
sample(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;),size = 3,replace = F) #-- Without replacement</code></pre>
<pre><code>## [1] &quot;C&quot; &quot;B&quot; &quot;E&quot;</code></pre>
<pre class="r"><code>set.seed(123)
sample(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;),size = 3,replace = T) #-- With replacement</code></pre>
<pre><code>## [1] &quot;C&quot; &quot;C&quot; &quot;B&quot;</code></pre>
</div>
<div id="example" class="section level2">
<h2>Example</h2>
<pre class="r"><code>set.seed(5)
sample(1:10,size=2,replace = T)</code></pre>
<pre><code>## [1] 2 9</code></pre>
<pre class="r"><code>set.seed(6)
sample(100,size=5)</code></pre>
<pre><code>## [1] 53 10 45 78 56</code></pre>
</div>
<div id="unequal-probability-sampling" class="section level2">
<h2>Unequal Probability Sampling</h2>
<pre class="r"><code>set.seed(7)
sample(c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;),size = 2,prob = c(0.1,0.4,0.5))</code></pre>
<pre><code>## [1] &quot;A&quot; &quot;C&quot;</code></pre>
</div>
<div id="similating-coin-tosses" class="section level2">
<h2>Similating Coin Tosses</h2>
<ul>
<li>An unbiased coin is tossed 10 times. Lets see the output of the tosses.</li>
</ul>
<pre class="r"><code>set.seed(100)
sample(c(&quot;H&quot;,&quot;T&quot;),10,replace = T)</code></pre>
<pre><code>##  [1] &quot;T&quot; &quot;H&quot; &quot;T&quot; &quot;T&quot; &quot;H&quot; &quot;H&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;H&quot;</code></pre>
<ul>
<li>Suppose now the probability of head is 2/6</li>
</ul>
<pre class="r"><code>set.seed(100)
sample(c(&quot;H&quot;,&quot;T&quot;),10,replace = T,prob = c(2/6,4/6))</code></pre>
<pre><code>##  [1] &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;H&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot;</code></pre>
</div>
<div id="find-the-proportion-of-heads-tails-in-long-run" class="section level2">
<h2>Find the Proportion of heads &amp; tails in long run</h2>
<pre class="r"><code>prop=NULL
size1=seq(100,10000,by=1000)
size2=seq(20000,500000,by=10000)
size=c(size1,size2)
for (n in size)
{
  x=sample(0:1,n,rep=T)
  prop=c(prop,sum(x)/n)
}
plot(size,prop,type=&quot;l&quot;)
abline(0.5,0)</code></pre>
</div>
<div id="find-the-proportion-of-heads-tails-in-long-run-1" class="section level2">
<h2>Find the Proportion of heads &amp; tails in long run</h2>
<pre><code>##  [1]    100   1100   2100   3100   4100   5100   6100   7100   8100   9100
## [11]  20000  30000  40000  50000  60000  70000  80000  90000 100000 110000
## [21] 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000
## [31] 220000 230000 240000 250000 260000 270000 280000 290000 300000 310000
## [41] 320000 330000 340000 350000 360000 370000 380000 390000 400000 410000
## [51] 420000 430000 440000 450000 460000 470000 480000 490000 500000</code></pre>
<pre><code>##  [1] 0.4800000 0.5100000 0.4985714 0.4880645 0.5026829 0.4905882 0.5039344
##  [8] 0.5021127 0.5004938 0.5057143 0.4978500 0.5019333 0.5033500 0.5027600
## [15] 0.5003167 0.5004000 0.4984125 0.5031000 0.4990700 0.4997818 0.4995667
## [22] 0.4988692 0.5021143 0.5017067 0.5019000 0.4986529 0.5001111 0.5005684
## [29] 0.5001250 0.4984714 0.4992182 0.4990478 0.4965500 0.4987200 0.4986769
## [36] 0.4991741 0.4989179 0.5002103 0.4991067 0.4998323 0.5003156 0.4998909
## [43] 0.4985824 0.4995286 0.5017111 0.5003432 0.4990737 0.5005205 0.4994575
## [50] 0.4997585 0.4988833 0.4997023 0.5001773 0.5009356 0.5003457 0.5004979
## [57] 0.5000729 0.4997633 0.4996940</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="finding-probabilities" class="section level2">
<h2>Finding Probabilities</h2>
<div id="fact" class="section level3">
<h3>Fact</h3>
<p>Probability of any event A can be interpreted as the long term relative frequency of the event A, i.e.,
<span class="math inline">\(\frac{no.\;of\;repetitions\;resulting\;in\;A}{total\;number\;of\;repetitions}\)</span>
<span class="math inline">\(as\;n\rightarrow\infty\)</span></p>
<ul>
<li>Hence for computing the probability of any event A by simulation, we shall simulate a large number <span class="math inline">\(n\)</span> of cases and count the number of times the event A has occurred. If this number is <span class="math inline">\(m\)</span>, then the probability of the event A can be approximated by <span class="math inline">\(\frac{m}{n}\)</span></li>
</ul>
</div>
</div>
<div id="drawing-a-card" class="section level2">
<h2>Drawing a Card</h2>
<ul>
<li>A card is drawn from a full pack of 52 cards. Find the probability that the drawn card is a picture card (i.e., king, queen or jack).</li>
</ul>
<pre class="r"><code>set.seed(125)
pic=NULL
for(i in 1:10000)
{
  x=sample(52,size = 1)
  if(any(x%%13==c(11,12,0)))
  {
    pic[i]=1
  }
  else pic[i]=0
}
sum(pic)/10000</code></pre>
<pre><code>## [1] 0.2287</code></pre>
<ul>
<li>Because, <strong>king</strong>= <span class="math inline">\(11^{th}\)</span> no. card, <strong>queen</strong>=<span class="math inline">\(12^{th}\)</span> no. card,<strong>jack</strong>=<span class="math inline">\(13^{th}\)</span> no. card.</li>
</ul>
</div>
<div id="divisibility-test" class="section level2">
<h2>Divisibility Test</h2>
<ul>
<li>A number is chosen at random from 1 to 1000. Find the probability that it is divisible by 3, 5 or 6.</li>
</ul>
<pre class="r"><code>count=0
for(i in 1:100000)
{
  num=sample(1000,1)
  if(num%%3==0||num%%5==0||num%%6==0)
  {
    count=count+1
  }
}
count/100000</code></pre>
<pre><code>## [1] 0.46794</code></pre>
</div>
<div id="urn-ball-problem" class="section level2">
<h2>Urn-Ball Problem</h2>
<ul>
<li>Suppose an urn contains 7 white and 5 black balls. 3 balls are chosen at random without replacement. Find the probability that :
<ul>
<li>all the 3 balls are white</li>
<li>2 are white and 1 is black.</li>
</ul></li>
</ul>
</div>
<div id="urn-ball-problem-1" class="section level2">
<h2>Urn-Ball Problem</h2>
<pre class="r"><code>count1=0; count2=0
balls= as.factor(c(rep(&quot;W&quot;,7),rep(&quot;B&quot;,5)))
for ( i in 1:10000)
{
chosen= sample(balls,3)
if (all(chosen==&quot;W&quot;)) count1=count1+1
if (table(chosen)[&quot;W&quot;]==2) count2=count2+1
}
count1/10000; count2/10000</code></pre>
<pre><code>## [1] 0.1565</code></pre>
<pre><code>## [1] 0.4859</code></pre>
</div>
<div id="birthday-problem" class="section level2">
<h2>Birthday Problem</h2>
<ul>
<li>In a class of 25 students, find the probability that at least two students share the same birthday.</li>
</ul>
<pre class="r"><code>count=0
for(i in 1:500)
{
  ##-- drawing samples by SRSWR --##
  class=sample(365,25,replace = T)
  if(length(unique(class))&lt;length(class))
  {
    count=count+1
  }
}
count/500</code></pre>
<pre><code>## [1] 0.574</code></pre>
</div>
<div id="card-shiffting" class="section level2">
<h2>Card Shiffting</h2>
<ul>
<li><p>Often we speak of well-shuffled deck of cards.</p></li>
<li><p>When we shuffle a deck by hand, the shuffling is always imperfect (not random)</p></li>
<li><p>We can simulate these imperfect shuffling in computer.</p></li>
</ul>
</div>
<div id="cut-shuffle" class="section level2">
<h2>Cut Shuffle</h2>
<ul>
<li><p>The simplest method is “cutting” the deck.</p></li>
<li><p>We cut the deck at some random point chosen somewhere around the middle of the deck.</p></li>
<li><p>Then put the lower part on the top of the upper part.</p></li>
<li><p>We shall simulate this shuffle.</p></li>
</ul>
</div>
<div id="simulating-a-cut-shuffle" class="section level2">
<h2>Simulating a Cut Shuffle</h2>
<pre class="r"><code>cut=function(deck)
{
  #choose a random cut point near middle
  x=rbinom(1,52,0.5)
  temp=c(deck[(x+1):52],deck[1:x])
  return(temp)
}
cut(1:52)</code></pre>
<pre><code>##  [1] 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48
## [26] 49 50 51 52  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21
## [51] 22 23</code></pre>
</div>
<div id="riffle-shuffle" class="section level2">
<h2>Riffle Shuffle</h2>
<ul>
<li><p>A much more reliable way is the rifle shuffle ( <em>also known as Faro shuffle or dovetail shuffle</em>)</p></li>
<li><p>First split the deck into two parts just as in the cut method.</p></li>
<li><p>Take the top half in left hand, and the other half in your right.</p></li>
<li><p>Release the cards randomly from both the hands.</p></li>
<li><p>Mathematically, if at any stage there are <span class="math inline">\(a\)</span> cards in your left hand and <span class="math inline">\(b\)</span> cards in your right, then the next card comes from the left hand with probability <span class="math inline">\(\frac{a}{a+b}\)</span> and from the right with probability <span class="math inline">\(\frac{b}{a+b}\)</span>.</p></li>
</ul>
</div>
<div id="simulating-riffle-shuffle" class="section level2">
<h2>Simulating Riffle Shuffle</h2>
<pre class="r"><code>riffle=function(deck)
{
  n=length(deck)
  x=rbinom(1,52,0.5)
  
  left=deck[1:x]; right=deck[(x+1):52]; k=0;
  
  a=length(left); b=length(right); tab=NULL;
  
  for(i in 1:52 )
  {
    ind=rbinom(1,1,a/(a+b))
    
    if(ind==1)
    {
      tab[k+1]=left[a]
      
      left=left[1:(a-1)]
      
      k=k+1; a=a-1
    }
    else
    {
      tab[k+1]=right[b]
      
      right=right[1:(b-1)]
      
      k=k+1; b=b-1
    }
  }
  return(tab)
}</code></pre>
</div>
<div id="simulating-riffle-shuffle-1" class="section level2">
<h2>Simulating Riffle Shuffle</h2>
<pre class="r"><code>riffle(1:52)</code></pre>
<pre><code>##  [1] 26 52 25 51 50 49 48 24 23 22 21 20 47 19 18 46 17 16 45 15 44 43 14 42 41
## [26] 40 39 13 12 11 38 10  9  8  7 37  6 36 35 34 33  5  4 32  3 31 30  2 29 28
## [51] 27  1</code></pre>
</div>
<div id="simulating-random-variables" class="section level2">
<h2>Simulating Random Variables</h2>
<ul>
<li><p>We can simulate a Uniform(0,1) variable by the command <strong>runif()</strong></p></li>
<li><p>This can be used to generate random variables from other discrete and continuous as well.</p></li>
<li><p>Suppose we want to generate a Bernoulli random variable with probability of success 0.7</p></li>
</ul>
<pre class="r"><code>bernoulli=function(prob)
{
  u=runif(1); x=NULL;
  if(u&lt;prob) x=1
  else x=0
  return(x)
}

bernoulli(0.7)</code></pre>
<pre><code>## [1] 0</code></pre>
</div>
<div id="using-it-farther" class="section level2">
<h2>Using it farther</h2>
<ul>
<li>Suppose we want to simulate a Geometric(0.8) random variable.</li>
</ul>
<pre class="r"><code>x=1
y=bernoulli(0.8)
while(y!=1)
{
  y=bernoulli(0.8)
  x=x+1
}
x</code></pre>
<pre><code>## [1] 1</code></pre>
</div>
<div id="much-complicated-ones" class="section level2">
<h2>Much Complicated Ones</h2>
<ul>
<li><p>How can we generate poisson or a Hypergeometric random variable using the above technique ?</p></li>
<li><p>For this we need to take the help of the following fact :</p></li>
</ul>
<div id="fact-1" class="section level3">
<h3>Fact</h3>
<p>Suppose we want to generate <span class="math inline">\(X\)</span> having p.m.f.
<span class="math inline">\(P(X=x_i)=p_i\;\;\forall i=0,1,2,...\;\;\sum{p_i}=1\)</span>. We generate <span class="math inline">\(U\sim Uni(0,1)\)</span> and set
<span class="math display">\[X = \left\{ \begin{array}{rcl}
x_0 &amp; if &amp; U&lt;p_0\\ x_1 &amp; if &amp; p_0\leqslant U&lt;{p_0+p_1} \\.&amp;.\\.&amp;.\\x_j &amp; if &amp; \sum^{i-1}_{j=0}p_j\leqslant U&lt;\sum^{i}_{j=0}p_j\\. &amp;.\\. &amp;.\\. &amp;.\end{array}\right.\]</span></p>
</div>
<div id="algorithm" class="section level3">
<h3>Algorithm</h3>
<ul>
<li><p>The preceding fact can be written as :</p>
<ul>
<li>Generate a random <span class="math inline">\(U\sim U(0,1)\)</span></li>
<li>If <span class="math inline">\(U&lt;p_0\)</span> stop and set <span class="math inline">\(X=x_0\)</span></li>
<li>If <span class="math inline">\(U&lt;p_0+p_1\)</span> stop and set <span class="math inline">\(X=x_1\)</span></li>
<li>If <span class="math inline">\(U&lt;p_0+p_1+p_2\)</span> stop and set <span class="math inline">\(X=x_2\)</span></li>
<li>and so on…</li>
</ul></li>
</ul>
</div>
</div>
<div id="generating-poisson-distribution" class="section level2">
<h2>Generating Poisson Distribution</h2>
<pre class="r"><code>poi_mass=function(x,lambda)
{
  return(exp(-lambda)*(lambda^x)/factorial(x))
}

poi_sample=function(lambda)
{
  U=runif(1); i=0; cumprob=poi_mass(0,lambda)
  
  while(U&gt;cumprob)
  {
    i=i+1
    cumprob=cumprob+poi_mass(i,lambda)
  }
  return(i)
}
poi_sample(5)</code></pre>
<pre><code>## [1] 2</code></pre>
</div>
<div id="continuous-distributions" class="section level2">
<h2>Continuous Distributions</h2>
<ul>
<li>For continuous distributions we use the following fact :</li>
</ul>
<div id="fact-2" class="section level3">
<h3>Fact</h3>
<p>(<em>Probability Integral Transformation</em>) If <span class="math inline">\(X\)</span> has an absolutely continuous distribution, then the C.D.F of <span class="math inline">\(X\)</span>, <span class="math inline">\(F(x)\)</span> has <span class="math inline">\(U(0,1)\)</span> distribution.</p>
<ul>
<li><p>Suppose we want to generate <span class="math inline">\(X\)</span> from <span class="math inline">\(Exp(\lambda)\)</span> distribution.</p></li>
<li><p><span class="math display">\[F(x)=1-e^{\lambda x}\;=&gt; U\sim U(0,1)\]</span></p></li>
<li><p><span class="math display">\[X=-\frac{1}{\lambda}ln(1-U)\]</span> is the required random variable.</p></li>
</ul>
</div>
</div>
<div id="working-with-inbuilt-r-functions" class="section level2">
<h2>Working with inbuilt R functions</h2>
<ul>
<li>Suppose we want to generate random variables from <span class="math inline">\(N(\mu,{\sigma}^2)\)</span></li>
</ul>
<pre class="r"><code># 2 samples from N(5,2) Distribution
rnorm(n=2,mean=5,sd=sqrt(2))</code></pre>
<pre><code>## [1] 7.280889 6.274643</code></pre>
<ul>
<li>Now let us find <span class="math inline">\(P(X\leq x)\)</span> i.e., <span class="math inline">\(\Phi(\frac{x-\mu}{\sigma})\)</span></li>
</ul>
<pre class="r"><code># P(X&lt;=4) for N(5,2)

pnorm(4,mean=5,sd=sqrt(2))</code></pre>
<pre><code>## [1] 0.2397501</code></pre>
<pre class="r"><code># P(X&gt;7) for N(5,2)

pnorm(7,mean=5,sd=sqrt(2),lower.tail = F)</code></pre>
<pre><code>## [1] 0.0786496</code></pre>
<ul>
<li>We can also compute the normal quantiles <span class="math inline">\(z_\alpha\)</span></li>
</ul>
<pre class="r"><code># lower 0.05 point

qnorm(0.05,mean=5,sd=sqrt(2))</code></pre>
<pre><code>## [1] 2.673826</code></pre>
<pre class="r"><code># lower 0.01 point

qnorm(0.01,mean=5,sd=sqrt(2),lower.tail = F)</code></pre>
<pre><code>## [1] 8.289953</code></pre>
<ul>
<li>Can also compute normal density <span class="math inline">\(\phi(\frac{x-\mu}{\sigma})\)</span></li>
</ul>
<pre class="r"><code># density at x=2

dnorm(2,mean = 5,sd=sqrt(2))</code></pre>
<pre><code>## [1] 0.02973257</code></pre>
<pre class="r"><code># density at x=5
dnorm(5,mean=5,sd=sqrt(2))</code></pre>
<pre><code>## [1] 0.2820948</code></pre>
</div>
<div id="plotting-the-normal-density" class="section level2">
<h2>Plotting the normal density</h2>
<pre class="r"><code>x=seq(-3,3,by=0.01); y=dnorm(x,0,1)
plot(x,y,type=&quot;l&quot;,main=&quot;Density of N(0,1)&quot;,ylab=expression(phi(x)))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
</div>
<div id="other-standard-distributions-in-r" class="section level2">
<h2>Other Standard Distributions in R</h2>
<table>
<thead>
<tr class="header">
<th>Distribution</th>
<th align="left">Sample</th>
<th align="left">P(X&lt;=x)</th>
<th align="center">z_alpha</th>
<th align="center">Density</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binomial</td>
<td align="left">rbinom(n,size,prob)</td>
<td align="left">pbinom</td>
<td align="center">qbinom</td>
<td align="center">dbinom</td>
</tr>
<tr class="even">
<td>Poisson</td>
<td align="left">rpois(n,lambda)</td>
<td align="left">ppois</td>
<td align="center">qpois</td>
<td align="center">dpois</td>
</tr>
<tr class="odd">
<td>Neg.Binomial</td>
<td align="left">rnbinom(n,size,prob,mu)</td>
<td align="left">pnbinom</td>
<td align="center">qnbinom</td>
<td align="center">dnbinom</td>
</tr>
<tr class="even">
<td>Geometric</td>
<td align="left">rgeom(n,prob)</td>
<td align="left">pgeom</td>
<td align="center">qgeom</td>
<td align="center">dgeom</td>
</tr>
<tr class="odd">
<td>Hypergeometric</td>
<td align="left">rhyper(nn,m,n,k)</td>
<td align="left">phyper</td>
<td align="center">qhyper</td>
<td align="center">dhyper</td>
</tr>
<tr class="even">
<td>Uniform</td>
<td align="left">runif(n,min=0,max=1)</td>
<td align="left">punif</td>
<td align="center">qunif</td>
<td align="center">dunif</td>
</tr>
<tr class="odd">
<td>Exponential</td>
<td align="left">rexp(n,rate=1)</td>
<td align="left">pexp</td>
<td align="center">qexp</td>
<td align="center">dexp</td>
</tr>
<tr class="even">
<td>Cauchy</td>
<td align="left">rcauchy(n,location=0,scale=1)</td>
<td align="left">pcauchy</td>
<td align="center">qcauchy</td>
<td align="center">dcauchy</td>
</tr>
<tr class="odd">
<td>t</td>
<td align="left">rt(n,df,ncp)</td>
<td align="left">pt</td>
<td align="center">qt</td>
<td align="center">dt</td>
</tr>
<tr class="even">
<td>F</td>
<td align="left">rf(n,df1,df2,ncp)</td>
<td align="left">pf</td>
<td align="center">qf</td>
<td align="center">df</td>
</tr>
<tr class="odd">
<td>Chi-Square</td>
<td align="left">rchisq(n,df,ncp=0)</td>
<td align="left">pchisq</td>
<td align="center">qchisq</td>
<td align="center">dchisq</td>
</tr>
<tr class="even">
<td>Gamma</td>
<td align="left">rgamma(n,shape,rate,schale)</td>
<td align="left">pgamma</td>
<td align="center">qgamma</td>
<td align="center">dgamma</td>
</tr>
<tr class="odd">
<td>Beta</td>
<td align="left">rbeta(n,shape1,shape2,ncp)</td>
<td align="left">pbeta</td>
<td align="center">qbeta</td>
<td align="center">dbeta</td>
</tr>
<tr class="even">
<td>Multinommial</td>
<td align="left">rmultinom(n,size,prob)</td>
<td align="left">-</td>
<td align="center">-</td>
<td align="center">dmultinom</td>
</tr>
<tr class="odd">
<td>Mult.Normal</td>
<td align="left">rmnnorm(n,mean,sigma)</td>
<td align="left">-</td>
<td align="center">-</td>
<td align="center">dmvnorm</td>
</tr>
</tbody>
</table>
</div>
<div id="central-limit-theorem" class="section level2">
<h2>Central Limit Theorem</h2>
<div id="theorem" class="section level3">
<h3>Theorem</h3>
<ul>
<li><p>(<em>iid case</em>) Let <span class="math inline">\(X_1,X_2,...,X_n\)</span> be <em>iid</em> random variables with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\({\sigma}^2&lt;\infty\)</span> and <span class="math display">\[S_n=X_1+X_2+...+X_n\]</span>. Then, <span class="math inline">\(\frac{S_n-E(S_n)}{\sqrt{Var(S_n)}}\longrightarrow N(0,1)\)</span> as <span class="math inline">\(n\longrightarrow \infty\)</span>.</p></li>
<li><p><span class="math inline">\(U_1,U_2,...,U_n\)</span> are <em>iid</em> <span class="math inline">\(U(0,1)\)</span> variables. Then
<span class="math display">\[Z_n=\frac{U_1+U_2+...+U_n-\frac{n}{2}}{\sqrt{\frac{n}{12}}}\longrightarrow N(0,1)\;\;;\;as\;\;n\longrightarrow \infty\]</span></p></li>
</ul>
<pre class="r"><code>n=100
k=10000
U=runif(n*k)
M=matrix(U,n,k)
X=apply(M,2,sum)
Z=(X-n/2)/sqrt(n/12)
par(mfrow=c(1,2))
hist(Z)
qqnorm(Z)
qqline(Z,col=&quot;red&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-29-1.png" width="672" /></p>
</div>
</div>
<div id="law-of-laege-numbers" class="section level2">
<h2>Law of Laege Numbers</h2>
<ul>
<li><p><strong>The weak Law of large numbers</strong> says that for any <span class="math inline">\(\epsilon&gt;0\)</span> the sequence of probabilities <span class="math display">\[P({|\frac{S_n}{n}-\mu|&lt;\epsilon})\longrightarrow 1\;\;\;\;\;as \;\;n\longrightarrow \infty\]</span></p></li>
<li><p>Consider i.i.d. coin flips, that is, Bernoulli trials with <span class="math inline">\(p=\mu=\frac{1}2\)</span></p></li>
<li><p>We find the <span class="math inline">\(P({|\frac{S_n}{n}-\mu|&lt;\epsilon})\)</span> in R and illustrate the limiting behavior, with <span class="math inline">\(\epsilon=0.01\)</span></p></li>
</ul>
</div>
<div id="plotting-the-probability" class="section level2">
<h2>Plotting the Probability</h2>
<pre class="r"><code>wlln=function(n,eps,p)
{
  pbinom(n*p+n*eps,n,p)-pbinom(n*p-n*eps,n,p)
}
prob=NULL
for(n in 1:10000)
{
  prob[n]=wlln(n,eps=0.01,p=0.5)
}
plot(prob,type=&quot;l&quot;,xlab=&quot;n&quot;,ylab=expression(P(X&lt;=x)))</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-30-1.png" width="672" /></p>
</div>
<div id="strong-law-of-large-numbers" class="section level2">
<h2>Strong Law of large numbers</h2>
<ul>
<li><p>The strong law of large numbers says that <span class="math inline">\(\frac{S_n}n \longrightarrow \mu\;\;\;w.p.\;1\;;\;as\;\;n\longrightarrow \infty\)</span></p></li>
<li><p>Consider i.i.d. coin flips, that is, Bernoulli trials with <span class="math inline">\(p=\mu=\frac{1}2\)</span></p></li>
<li><p>The sum <span class="math inline">\(S_n\)</span> is a Binomial random variable.</p></li>
</ul>
</div>
<div id="illustrating-strong-law" class="section level2">
<h2>Illustrating Strong Law</h2>
<pre class="r"><code>slln=function(n,p)
{
  x=rbinom(1,size=n,prob=p)
  return(x)
}
value=NULL
for(i in 1:10000)
{
  value[i]=slln(i,0.5)/i
}
plot(value,type=&quot;l&quot;,xlab=&quot;n&quot;,ylab=&quot;Sample mean&quot;)
abline(h=0.5)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
</div>
<div id="family-planning" class="section level2">
<h2>Family Planning</h2>
<ul>
<li>Suppose a couple is planning to have children until they have one child of each sex. Assuming male and female child are equally probable, how may children can they expect to have ?</li>
</ul>
<pre class="r"><code>count=NULL
for(i in 1:1000)
{
  child=sample(c(0,1),1)
  while(length(unique(child))&lt;2)
  {
    child=c(child,sample(c(0,1),1))
  }
  count[i]=length(child)
}
mean(count)</code></pre>
<pre><code>## [1] 3.08</code></pre>
</div>
<div id="using-simulation-to-construct-tests" class="section level2">
<h2>Using Simulation to construct Tests</h2>
<ul>
<li><p>Simulation can be used to construct tests in situations where the <strong>exact sampling distribution</strong> of the test statistic is hard to find even under the null hypothesis.</p></li>
<li><p>More specially we use simulation to find the <span class="math inline">\(\alpha100\)</span>% cut-off points</p></li>
<li><p>Suppose we have a sample of 101 from Beta(5,b)</p></li>
<li><p>We want to test <span class="math inline">\(H_0:b=5\)</span> against <span class="math inline">\(H_1:b&lt;5\)</span></p></li>
<li><p>To get an idea about the nature of the test we plot the density function for different values of b.</p></li>
</ul>
</div>
<div id="plot-of-beta-densities" class="section level2">
<h2>Plot of Beta Densities</h2>
<pre class="r"><code>par(mfrow=c(1,3))
x=seq(0,1,by=0.01)
y1=dbeta(x,shape1 = 5,shape2 = 2)
y2=dbeta(x,shape1 = 5,shape2 = 5)
y3=dbeta(x,shape1 = 5,shape2 = 10)
plot(x,y1,type=&quot;l&quot;,xlab=&quot;b&lt;5&quot;)
abline(v=median(rbeta(101,shape1 = 5,shape2 = 2)),col=&quot;red&quot;)
plot(x,y2,type=&quot;l&quot;,xlab=&quot;b=5&quot;)
abline(v=median(rbeta(101,shape1=5,shape2=5)),col=&quot;red&quot;)
plot(x,y3,type=&quot;l&quot;,xlab=&quot;b&gt;5&quot;)
abline(v=median(rbeta(101,shape1=5,shape2=10)),col=&quot;red&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-33-1.png" width="672" /></p>
</div>
<div id="what-type-of-test-shall-we-perform" class="section level2">
<h2>What type of test shall we perform ?</h2>
<ul>
<li><p>From the figures we see that sample median can be used as a
test statistic.</p></li>
<li><p>Also a right tailed test based on the median will be appropriate</p></li>
<li><p>Thus we shall reject <span class="math inline">\(H_0\)</span> if the sample median exceeds some
value <span class="math inline">\(c\)</span>.</p></li>
<li><p>We want to find the test at 90% level of signficance.</p></li>
<li><p>We shall use simulation technique to find the cut-off point <span class="math inline">\(c\)</span>.</p></li>
</ul>
<pre class="r"><code>set.seed(100);prob=NULL; j=1
C=seq(0.2,0.9,by=0.001)
for ( c in C)
{
prob[j]=0
for(i in 1:100)
{
x=rbeta(101,shape1=5,shape2=5)
me=median(x)
if(me&gt;c) prob[j]=prob[j]+1
}
prob[j]=prob[j]/100
j=j+1
}
plot(C,prob,type=&quot;l&quot;)
abline(h=0.9,col=&quot;red&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-34-1.png" width="672" /></p>
</div>
<div id="now-lets-find-the-c" class="section level2">
<h2>Now lets find the c</h2>
<p>We continue to search the c for which <span class="math inline">\(P_{H_0}(me&gt;c)\)</span> is closet to 0.9</p>
<pre class="r"><code>C[which(prob&gt;0.89 &amp; prob&lt;0.91)]</code></pre>
<pre><code>## [1] 0.473 0.475</code></pre>
<pre class="r"><code>prob[which(C %in% C[which(prob&gt;0.89 &amp; prob&lt;0.91)])]</code></pre>
<pre><code>## [1] 0.9 0.9</code></pre>
<p>So, we can take c to be 0.473
Thus our test rule is: Reject <span class="math inline">\(H_0\)</span> if sample median exceeds 0.473</p>
</div>
<div id="generating-normal-variables" class="section level2">
<h2>Generating Normal Variables</h2>
<ul>
<li>Instead of using R inbuilt function, <em>rnorm()</em>, we can generate Normal variables from scratch.</li>
</ul>
<div id="fact-box-muller-transformation" class="section level3">
<h3>Fact: Box-Muller transformation</h3>
<p>let, <span class="math inline">\(U_1\)</span>,<span class="math inline">\(U_2\)</span><span class="math inline">\(\sim U(0,1)\)</span></p>
<p><span class="math display">\[Z_1=\sqrt{-2 ln U_1} cos(2\pi U_2)\]</span>
<span class="math display">\[Z_2=\sqrt{-2 ln U_1} sin(2\pi U_2)\]</span></p>
<p>Then, <span class="math inline">\(Z_1,Z_2 \sim N(0,1)\)</span> independently.</p>
<p>So, to generate <span class="math inline">\(Y \sim N(\mu , {\sigma}^2)\)</span>; we use, <span class="math inline">\(Y=\mu +\sigma Z\)</span> where, <span class="math inline">\(Z \sim N(0,1)\)</span>.</p>
<pre class="r"><code>normal=function(n)
{
  U1 = runif(n)
  U2 = runif(n)
  C = sqrt(-2*log(U1))
  Z1 = C*cos(2*pi*U2)
  Z2 = C*sin(2*pi*U2)
  return(Z1)
}

n = 100000
Z = normal(n)

hist(Z,prob=T,col=rainbow(12))

#-- note that, rainbow() is a graphical function, which gives multiple color.
curve(dnorm(x),-3,3,
      add=T,lwd=4)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
</div>
</div>
<div id="generating-bivariate-normal-variables" class="section level2">
<h2>Generating Bivariate Normal Variables</h2>
<div id="fact-3" class="section level3">
<h3>Fact:</h3>
<p>If <span class="math inline">\((X,Y) \sim N_2(0,0,1,1,\rho)\)</span>, then <span class="math inline">\(Z_1=X\)</span> and <span class="math inline">\(Z_2=\frac{(Y-\rho X)}{\sqrt{1-{\rho}^2}}\)</span> are iid <span class="math inline">\(N(0,1)\)</span>, where, <span class="math inline">\(-1&lt;\rho&lt;1\)</span></p>
<p>Equivalently, if we generate <span class="math inline">\(Z_1\)</span>,<span class="math inline">\(Z_2\)</span> iid <span class="math inline">\(N(0,1)\)</span>, then setting <span class="math inline">\(X=Z_1\)</span> and <span class="math inline">\(Y=(1-{\rho}^2)Z_2+\rho Z_1\)</span> gives a pair of random variables that have <span class="math inline">\(N_2(0,0,1,1,\rho)\)</span> distribution.</p>
<pre class="r"><code>binorm=function(n,rho)
{
  x = numeric(n); y&lt;- numeric(n)
  for (i in 1:n)
  {
    z1 = normal(1)
    z2 = normal(1)
    x[i] = z1
    y[i] = rho*z1+sqrt(1-rho^2)*z2
  }
  return(cbind(x,y))
}
n = 1000 ;rho = -0.5

data = binorm(n,rho)

##-- Plotting Bivariate Normal Data --##

plot(data,
     pch=19,
     xlab=&quot;X&quot;,
     ylab = &quot;Y&quot;)

abline(lm(data[,2]~data[,1]),col=&quot;red&quot;,
       v=mean(data[,1]),
       h=mean(data[,2]),
       lwd=3)

legend(&quot;topright&quot;,legend = c(paste(&quot;mean(X)= &quot;,round(mean(data[,1]),3)),
                              paste(&quot;Var(X)= &quot;,round((sd(data[,1]))^2,3)),
                              paste(&quot;mean(Y)= &quot;,round(mean(data[,2]),3)),
                              paste(&quot;Var(Y)= &quot;,round((sd(data[,2]))^2,3)),
                              paste(&quot;samp corr.= &quot;,round(cor.test(data[,1],data[,2])$estimate,2))),
       cex=0.66)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-38-1.png" width="672" /></p>
</div>
</div>
<div id="monte-carlo-simulation" class="section level2">
<h2>Monte Carlo Simulation</h2>
<ul>
<li><p>We know that sample average <span class="math inline">\(\bar{x}\)</span> converges to population mean by consistency property.</p></li>
<li><p>Thus expected value of any function can be approximated by the sample average.</p></li>
<li><p>Thus <span class="math inline">\(\frac{1}{N} \sum_{i=1}^N{f(X_i)} \longrightarrow E(f(X))\)</span> with probability 1 as <span class="math inline">\(N \longrightarrow \infty\)</span> if <span class="math inline">\(X_1,X_2,...\)</span> are iid sequence of random variables with the same distribution as <span class="math inline">\(X\)</span>.</p></li>
<li><p>A Monte Carlo method for estimating <span class="math inline">\(E(f(X))\)</span> is a numerical method based on the approximation <span class="math display">\[Z_N^{MC}=E[f(X)]\approx \frac{1}{N} \sum_{i=1}^N(f(X_1))\]</span> where <span class="math inline">\(X_1,X_2,...\)</span> are iid sequence of random variables with same distribution as <span class="math inline">\(X\)</span>.</p></li>
</ul>
</div>
<div id="bias-variance" class="section level2">
<h2>Bias &amp; Variance</h2>
<ul>
<li>The Monte Carlo estimate <span class="math inline">\(Z_N^{MC}\)</span> for <span class="math inline">\(E(f(X))\)</span>, has <span class="math display">\[bias(Z_N^{MC})=0\]</span> and <span class="math display">\[MSE(Z_N^{MC})=Var(Z_N^{MC})=\frac{1}{N} Var(f(X))\]</span></li>
</ul>
</div>
<div id="monte-carlo-integration" class="section level2">
<h2>Monte Carlo Integration</h2>
<ul>
<li><p>Consider the integral <span class="math inline">\({\int}_a^bf(x)dx\)</span></p></li>
<li><p>Objective is to approximate this integral</p></li>
<li><p>Let <span class="math inline">\(X_1,X_2,...\)</span> be iid <span class="math inline">\(U(a,b)\)</span>, i.e., density of <span class="math inline">\(X_j\)</span> is <span class="math inline">\(\phi(x)=\frac{1}{b-a}I_{[a,b]}\)</span></p></li>
<li><p>Then <span class="math display">\[{\int}_a^bf(x)dx=(b-a){\int}_a^bf(x) \phi(x)dx=(b-a)E(f(X))\approx \frac{b-a}{N} \sum_{i=1}^N{f(X_j)}\]</span> for large <span class="math inline">\(N\)</span></p></li>
</ul>
<div id="example-1" class="section level3">
<h3>Example</h3>
<ul>
<li><p>Evaluate the integral <span class="math inline">\({\int}_0^{2\pi} e^{k\:cos(x)}dx\)</span></p></li>
<li><p>We, grnerate samples <span class="math inline">\(X_j\)</span> from <span class="math inline">\(U(0,2\pi)\)</span></p></li>
<li><p>Then use the approximation <span class="math display">\[{\int}_0^{2\pi} e^{k\:cos(x)}dx \approx \frac{2\pi}{N} \sum_{j=1}{e^{k\:cox(X_j)}}\]</span></p></li>
</ul>
<pre class="r"><code>set.seed(123)
N = 1000
x = runif(N,min=0,max=(2*pi))
value = sum(exp(cos(x)))
value = (2*pi)*value/N
value</code></pre>
<pre><code>## [1] 7.901431</code></pre>
</div>
<div id="another-example" class="section level3">
<h3>Another Example</h3>
<ul>
<li><p><strong>Problem:</strong> Generate the c.d.f of <span class="math inline">\(N(0,1)\)</span> for several values of the argument and then compare its accuracy.</p></li>
<li><p>The normal c.d.f can be expressed as, <span class="math display">\[\Phi(t)= {\int}_{-\infty}^t \frac{1}{\sqrt{2\pi}}e^{\frac{x^2}{2}}dx\]</span></p></li>
<li><p>We shall use Monte Carlo method to estimate <span class="math inline">\(\phi(t)\)</span> as, <span class="math display">\[\phi{(t)} \approx \frac{1}{n} \sum_{i=1}^n{I(X_i \le t)}\]</span> where, <span class="math inline">\(I(X_i \le t)=\)</span> 1 or 0 with prob. <span class="math inline">\(\phi(t)\)</span> or <span class="math inline">\(1-\phi(t)\)</span> respectively, and <span class="math inline">\(X_i\)</span>’s are random samples from <span class="math inline">\(N(0,1)\)</span>.</p></li>
</ul>
<pre class="r"><code>n = 1000
t = seq(-3,3,0.01)
x = NULL
phi.hat=NULL
phi=NULL
for(i in 1:length(t))
{
 x = rnorm(n)
 s = sum(x&lt;=t[i])
 phi.hat[i] = s/n
 phi[i] = pnorm(t[i])
}
par(mfrow = c(1,2))
plot(t,phi,main=&quot;Original c.d.f&quot;,col=&quot;red&quot;,pch=19)
plot(t,phi.hat,main=&quot;Estimated c.d.f&quot;,col=&quot;blue&quot;,pch=19)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-40-1.png" width="672" /></p>
</div>
</div>
<div id="an-assignment-problem" class="section level2">
<h2>An assignment Problem</h2>
<p><strong>Here, we have to do :</strong></p>
<ul>
<li><p>Draw a random sample of size 50 from <span class="math inline">\(N(1,2)\)</span></p></li>
<li><p>Draw another radom sample of size 1000 from the same distribution <span class="math inline">\(N(1,2)\)</span></p></li>
<li><p>Calculate the test statistic :<span class="math inline">\(T_n=\frac{\sqrt{n}(\bar{X_n}-1)}{s_n}\)</span></p></li>
<li><p>Repeat this 1000 times.</p></li>
<li><p>Draw histograms of the <span class="math inline">\(T_n\)</span>’s coming from two different samples of the same population <span class="math inline">\(N(0,1)\)</span></p></li>
<li><p>Copare these two histograms with the Standard Normal distribution.</p></li>
</ul>
<p><strong>Solution:</strong></p>
<ul>
<li>here, to plot histograms, instead of using the famous <em>ggplot2</em> package, I am using the basic R plotting function.</li>
</ul>
<pre class="r"><code>##--- Creating a Function to simulate 1000 test statistics for two different samples

simulation=function(len_1,len_2){

  A=NULL
  B=NULL
  
  for(i in 1:1000)
  {
    Sam_1=rnorm(len_1,1,sqrt(2))
    Sam_2=rnorm(len_2,1,sqrt(2))
    
    Tn_1=(sqrt(length(Sam_1))*((sum(Sam_1)/length(Sam_1))-1))/sqrt(var(Sam_1))
    
    Tn_2=(sqrt(length(Sam_2))*((sum(Sam_2)/length(Sam_2))-1))/sqrt(var(Sam_2))
    
    A=c(A,Tn_1)
    
    B=c(B,Tn_2)
    
  }
  Mat=as.data.frame(matrix(c(A,B),ncol=2,byrow = F))
  names(Mat)=c(&quot;Tn_1&quot;,&quot;Tn_2&quot;)
  return(Mat)
}

X=(simulation(50,1000)) # Data Table

X[1:10,] # Showing 1st 10 samples of the Data Table</code></pre>
<pre><code>##          Tn_1        Tn_2
## 1   0.8020946  0.20259551
## 2  -0.8509208 -1.40945355
## 3  -0.2805664 -1.05684656
## 4  -0.6615001 -0.44404425
## 5   2.3164142 -0.09538437
## 6  -2.3255364 -0.42208845
## 7  -0.2363790  0.60943958
## 8  -2.8176113 -0.40001562
## 9  -0.2177217 -2.25709292
## 10 -0.0575885  2.26107062</code></pre>
<pre class="r"><code># Writing a message

writeLines(paste(c(&quot;Omitting&quot;,&quot;the&quot;,&quot;rest&quot;,&quot;990&quot;,&quot;values&quot;)),sep=&quot; &quot;)</code></pre>
<pre><code>## Omitting the rest 990 values</code></pre>
<pre class="r"><code>##--- Histogram of the 1st Sample 

hist(X$Tn_1,
     col=&quot;red&quot;,
     xlab=&quot;Tn&quot;,
     ylab=&quot;Frequency&quot;,
     main=&quot;For the Sample 1&quot;,
     density = 50)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-41-1.png" width="672" /></p>
<pre class="r"><code>##--- Histogram of the 2nd Sample

hist(X$Tn_2,
     col=12,
     xlab=&quot;Tn&quot;,
     ylab=&quot;&quot;,
     main=&quot;For the Sample 2&quot;,
     density = 40)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-41-2.png" width="672" /></p>
<pre class="r"><code>##--- Preparing the density of the N(0,1)

a=seq(-3,3,by= 0.01) # Range of the sample points for N(0,1)

b=dnorm(a) # density of the N(0,1) for the above range.

##--- Comparing Plots :

hist(X$Tn_1,           # histogram for the Sample 1
     col=&quot;red&quot;,
      xlab=&quot;Tn&quot;,
      ylab=&quot;Frequency&quot;,
      main=&quot;Comparing Two Histograms coming from two\n different Samples of the same \nPopulation N(1,2) with the Standard Normal density&quot;,
     density = 50,
     axes=F,
     cex=4)
par(new=T)             # For Overlap the new plot
hist(X$Tn_2,          
      col=12,
      xlab=&quot;&quot;,
      ylab=&quot;&quot;,         # histogram for the Sample 2  
      main=&quot;&quot;,
     density = 40,
     axes = F)
par(new=T)             # For Overlap the new plot
plot(a,b,
     type =&quot;l&quot;,
     xlab=&quot;&quot;,
     ylab=&quot;&quot;,          # Density curve of the N(0,1)
     main = &quot;&quot;,
     axes = F, 
     col=&quot;darkgreen&quot;,
     lwd=3)

# Adding Legend

legend(&quot;topright&quot;,        
       legend = c(&quot;Sample 1&quot;,&quot;Sample 2&quot;,&quot;PDF-N(0,1)&quot;),
       fil=c(&quot;red&quot;,20,&quot;darkgreen&quot;),
       cex=0.6)

# Adding box

box()</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-41-3.png" width="672" /></p>
</div>
<div id="brownian-motion" class="section level2">
<h2>Brownian Motion</h2>
<ul>
<li><p>Note that the concepts on basics of Monte Carlo Simulation and various Random Distributions have been introduced lets focus on using Monte Carlo methods to simulate paths for various <a href="https://en.wikipedia.org/wiki/Stochastic_process">Stochastic Processes.</a></p></li>
<li><p>Standard Brownian Motion on <span class="math inline">\([0,T]\)</span> is a Stochastic Process <span class="math inline">\((W(t),0\leq t \leq T)\)</span> which satisfies some properties such as</p>
<ul>
<li><span class="math inline">\(W(0) = 0\)</span></li>
<li>For any <span class="math inline">\(k\)</span> and any <span class="math inline">\(0 \leq t_1 \leq .... \leq T\)</span>, the increments between any two successive <span class="math inline">\(W(t_i)-W(t_{i-1})\)</span> are independent.</li>
<li>The difference <span class="math inline">\(W(t)-W(s) \sim N(0,t-s)\)</span> for any <span class="math inline">\(0\leq s&lt;t \leq T\)</span></li>
</ul></li>
</ul>
<p>As a consequence of 1st and 2nd, <span class="math inline">\(W(t) \sim N(0,t)\)</span>.</p>
<p>On the other hand, Brownian Motion which is non-standard will have two parameters just like Normal Distribution known as <strong>drift</strong> and <strong>diffusion</strong>. Using <span class="math inline">\(W(t)\)</span> we therefore give a <strong>Stochastic Differential</strong> Equation for any Brownian Motion</p>
<p><span class="math display">\[Brownian\:motion\:with\:drift\: \mu \:and\:\:diffusion\:\:coefficient\: \sigma^2\:\:through\:\:the\;SDE\]</span> <span class="math display">\[dX(t)=\mu(t)dt+\sigma(t)dW(t)\]</span></p>
<p><strong>Sample Paths Generations</strong></p>
<p>Solving the SDE presented above we can write the equation in terms of <span class="math inline">\(X(t_i),\mu(s),\sigma(s)\)</span> <span class="math display">\[X(t_{i+1})=X(t_i)+\int_{t_i}^{t_{i+1}}\mu(s)ds+\sqrt{\int_{t_i}^{t_{i+1}}{\sigma^2(u)du Z_{i+1}}}\]</span> Hence let us look at the code to generate paths where I have assumed <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> to be constant.</p>
<pre class="r"><code>Brownian = function() # This is a function to generate Browninan with drift 0.04 and diffusion 0.7
{
    paths = 10
    count = 5000
    interval = 5/count
    sample = matrix(0,nrow=(count+1),ncol=paths)
    for(i in 1:paths)
    {
        sample[1,i] = 5
        for(j in 2:(count+1))
        {
            sample[j,i] = sample[j-1,i]+interval*0.04+((interval)^.5)*rnorm(1,0,1)*0.7
        }
    }   
    cat(&quot;E[W(2)] = &quot;,mean(sample[2001,]),&quot;\n&quot;)
    cat(&quot;E[W(5)] = &quot;,mean(sample[5001,]),&quot;\n&quot;)
    matplot(sample,main=&quot;Brownian&quot;,xlab=&quot;Time&quot;,ylab=&quot;Path&quot;,type=&quot;l&quot;)
}

StandardBrownian = function() # This is a function to generate Standard Browninan with drift 0 and diffusion 1
{
    paths = 10
    count = 5000
    interval = 5/count
    sample = matrix(0,nrow=(count+1),ncol=paths)
    for(i in 1:paths)
    {
        sample[1,i] = 0
        for(j in 2:(count+1))
        {
            sample[j,i] = sample[j-1,i]+((interval)^.5)*rnorm(1)
        }
    }   
    cat(&quot;E[W(2)] = &quot;,mean(sample[2001,]),&quot;\n&quot;)
    cat(&quot;E[W(5)] = &quot;,mean(sample[5001,]),&quot;\n&quot;)
    matplot(sample,main=&quot;Standard Brownian&quot;,xlab=&quot;Time&quot;,ylab=&quot;Path&quot;,type=&quot;l&quot;)
}
StandardBrownian()</code></pre>
<pre><code>## E[W(2)] =  -0.2205643 
## E[W(5)] =  -0.2023842</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
<pre class="r"><code>Brownian()</code></pre>
<pre><code>## E[W(2)] =  5.321014 
## E[W(5)] =  5.338038</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-42-2.png" width="672" /></p>
</div>
